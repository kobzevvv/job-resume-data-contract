#!/usr/bin/env node

/**
 * Test PDF Resume Processing - Size Limit Issue
 * Test with Russian PDF resume to verify database logging works for PDFs
 */

import { readFileSync } from 'fs';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// Configuration
const WORKER_URL = process.env.WORKER_URL || 'https://resume-processor-worker.dev-a96.workers.dev';
const PDF_FILE = join(__dirname, 'tests', 'sample-resumes', 'pdf', 'international', 'ĞœĞ°ÑˆĞ¸Ğ½ Ğ“ĞµĞ¾Ñ€Ğ³Ğ¸Ğ¹ ĞŸĞ°Ğ²Ğ»Ğ¾Ğ²Ğ¸Ñ‡.pdf');

console.log('ğŸ” Test PDF Resume Processing - Size Limit Issue');
console.log('===============================================\n');

/**
 * Test with Russian PDF resume
 */
async function testPdfResumeProcessing() {
  try {
    console.log('ğŸ“‹ Step 1: Loading PDF Resume');
    console.log('-----------------------------');
    
    // Read the PDF file as base64
    const pdfBuffer = readFileSync(PDF_FILE);
    const pdfBase64 = pdfBuffer.toString('base64');
    
    console.log(`ğŸ“„ PDF file: ĞœĞ°ÑˆĞ¸Ğ½ Ğ“ĞµĞ¾Ñ€Ğ³Ğ¸Ğ¹ ĞŸĞ°Ğ²Ğ»Ğ¾Ğ²Ğ¸Ñ‡.pdf`);
    console.log(`ğŸ“Š PDF size: ${pdfBuffer.length} bytes`);
    console.log(`ğŸ“Š Base64 size: ${pdfBase64.length} characters`);
    console.log(`ğŸŒ Language: Russian`);
    console.log(`ğŸ“ Input preview: PDF document (base64 encoded)\n`);
    
    // Check if the request would be too large
    const testRequest = {
      resume_pdf: pdfBase64,
      language: "ru",
      options: {
        flexible_validation: true,
        strict_validation: false
      }
    };
    
    const requestSize = JSON.stringify(testRequest).length;
    console.log(`ğŸ“Š Request size: ${requestSize} characters`);
    console.log(`ğŸ“Š Request size: ${(requestSize / 1024).toFixed(2)} KB`);
    
    if (requestSize > 50000) {
      console.log('âŒ Request too large! Exceeds 50KB limit');
      console.log('ğŸ” This explains why we got "413 Payload Too Large" error');
      console.log('');
      console.log('ğŸ“‹ Solutions:');
      console.log('1. **Use smaller PDF files** (under 50KB total request size)');
      console.log('2. **Increase worker payload limit** in wrangler.toml');
      console.log('3. **Test with text resumes** (which work perfectly)');
      console.log('4. **Use PDF processing endpoint** if available');
      console.log('');
      console.log('ğŸ¯ For now, let\'s verify that our database logging fix works with text resumes:');
      console.log('âœ… Text resumes: WORKING (inputPreview + resumeData fields stored)');
      console.log('âŒ PDF resumes: BLOCKED by size limit');
      return;
    }
    
    console.log('ğŸš€ Step 2: Sending PDF Request to Worker');
    console.log('---------------------------------------');
    console.log(`ğŸ”— Worker URL: ${WORKER_URL}`);
    console.log('ğŸ“¤ Sending POST request to /process-resume...\n');
    
    const startTime = Date.now();
    const response = await fetch(`${WORKER_URL}/process-resume`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(testRequest),
    });
    
    const processingTime = Date.now() - startTime;
    console.log(`â±ï¸  Request processing time: ${processingTime}ms`);
    console.log(`ğŸ“Š Response status: ${response.status} ${response.statusText}`);
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error('âŒ Request failed:', errorText);
      return;
    }
    
    const responseData = await response.json();
    console.log('âœ… Request completed successfully\n');
    
    /**
     * Analyze API Response
     */
    console.log('ğŸ“Š Step 3: API Response Analysis');
    console.log('-------------------------------');
    console.log(`âœ… Success: ${responseData.success}`);
    console.log(`ğŸ“Š Has data: ${responseData.data ? 'YES' : 'NO'}`);
    console.log(`â±ï¸  Processing time: ${responseData.processing_time_ms}ms`);
    console.log(`ğŸ“ Errors count: ${responseData.errors?.length || 0}`);
    
    if (responseData.data) {
      console.log(`ğŸ¯ Desired titles: ${responseData.data.desired_titles?.length || 0}`);
      console.log(`ğŸ“ Summary: ${responseData.data.summary ? 'YES' : 'NO'}`);
      console.log(`ğŸ› ï¸  Skills: ${responseData.data.skills?.length || 0}`);
      console.log(`ğŸ’¼ Experience: ${responseData.data.experience?.length || 0}`);
    }
    
    /**
     * Database Verification
     */
    console.log('\nğŸ—„ï¸  Step 4: Database Verification');
    console.log('--------------------------------');
    console.log('Run these SQL queries to check the logs:');
    console.log('');
    console.log('-- Check recent entries');
    console.log('SELECT request_id, timestamp, json_extract(payload, "$.inputPreview") as input_preview, json_extract(payload, "$.success") as success FROM request_logs_simple WHERE endpoint = "/process-resume" ORDER BY created_at DESC LIMIT 3;');
    
    /**
     * Summary
     */
    console.log('\nğŸ“‹ Step 5: Test Summary');
    console.log('----------------------');
    console.log(`âœ… API Response Generated: ${responseData.success ? 'YES' : 'NO'}`);
    console.log(`ğŸ“Š Data Extracted: ${responseData.data ? 'YES' : 'NO'}`);
    console.log(`ğŸš€ Worker Deployed: YES (Version: fcdd5397-782c-45cf-a973-293212312c32)`);
    console.log(`ğŸ—„ï¸  Database Logging: Should include inputPreview and resumeData fields`);
    
    if (responseData.success && responseData.data) {
      console.log('\nğŸ‰ SUCCESS: PDF resume processing works!');
      console.log('ğŸ” Check database logs for inputPreview and resumeData fields');
    } else {
      console.log('\nâš ï¸  ISSUE: PDF resume processing failed');
      console.log('ğŸ” Check the errors and unmapped fields for details');
    }
    
  } catch (error) {
    console.error('âŒ Test failed:', error.message);
    console.error('Stack trace:', error.stack);
  }
}

// Run the test
testPdfResumeProcessing();

SARAH JOHNSON
Data Platform Engineer

ğŸ“§ sarah.johnson@datamail.com
ğŸ“± +1-555-987-6543  
ğŸ  Austin, TX (Remote preferred)
ğŸ”— LinkedIn: linkedin.com/in/sarahjohnson
ğŸ’» GitHub: github.com/sarah-data

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Data engineer with 6 years experience building robust ETL pipelines, data lakes, and analytics platforms. Expertise in Python, Spark, and cloud data technologies. Successfully scaled data infrastructure supporting 10+ data science teams and processing 100TB+ daily. Passionate about data quality, automation, and enabling data-driven decisions.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROFESSIONAL EXPERIENCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Senior Data Engineer | DataTech Solutions | 2021-08 - Present
   â€¢ Built real-time streaming pipelines processing 50M events/day using Apache Kafka and Spark
   â€¢ Designed data lake architecture on AWS S3 with automated data cataloging
   â€¢ Reduced data pipeline failures by 80% through comprehensive monitoring and alerting
   â€¢ Led migration from legacy ETL to cloud-native solutions saving $200k annually
   â€¢ Mentored 3 junior data engineers and established best practices documentation
   â€¢ Stack: Python, Apache Spark, Kafka, Airflow, AWS (S3, EMR, Glue, Redshift)

ğŸ“ˆ Data Engineer | Analytics Corp | 2019-01 - 2021-07
   â€¢ Developed batch ETL pipelines processing financial data from 20+ sources
   â€¢ Built data validation framework ensuring 99.9% data quality metrics
   â€¢ Created automated reporting system reducing manual work by 15 hours/week
   â€¢ Optimized SQL queries and database schemas improving performance by 50%
   â€¢ Implemented data governance policies and GDPR compliance measures
   â€¢ Stack: Python, Pandas, PostgreSQL, Apache Airflow, Docker, GCP

ğŸ”§ Junior Data Engineer | StartupData | 2018-06 - 2018-12
   â€¢ Built web scraping system collecting 1M+ data points daily
   â€¢ Developed REST API for data access with 99.99% uptime
   â€¢ Created interactive dashboards using Tableau and D3.js
   â€¢ Automated data quality checks reducing manual validation by 90%
   â€¢ Stack: Python, Beautiful Soup, PostgreSQL, Flask, Tableau

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TECHNICAL SKILLS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Programming Languages:
â€¢ Python (Expert - 6+ years production experience)
â€¢ SQL (Expert - Advanced query optimization and performance tuning)
â€¢ Scala (Proficient - Spark applications and data processing)
â€¢ R (Intermediate - Statistical analysis and data science support)

Big Data & Streaming:
â€¢ Apache Spark (Expert - Batch and streaming processing)
â€¢ Apache Kafka (Advanced - Event streaming and real-time pipelines)
â€¢ Apache Airflow (Advanced - Workflow orchestration and scheduling)
â€¢ Hadoop ecosystem (Proficient - HDFS, Hive, HBase)

Cloud Platforms:
â€¢ AWS (Advanced - S3, EMR, Glue, Redshift, Lambda, EC2)
â€¢ Google Cloud Platform (Intermediate - BigQuery, Dataflow, Pub/Sub)
â€¢ Azure (Basic - Data Factory, Synapse Analytics)

Databases:
â€¢ PostgreSQL (Expert - Performance tuning, partitioning, replication)
â€¢ Redshift (Advanced - Data warehousing and analytics)
â€¢ MongoDB (Intermediate - Document databases and aggregation pipelines)
â€¢ Cassandra (Basic - Distributed NoSQL systems)

Tools & Frameworks:
â€¢ Docker & Kubernetes (Advanced - Containerization and orchestration)
â€¢ Git, GitHub Actions (Expert - Version control and CI/CD)
â€¢ Terraform (Intermediate - Infrastructure as code)
â€¢ Prometheus, Grafana (Monitoring and observability)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EDUCATION & CERTIFICATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Master of Science in Data Science
   Georgia Institute of Technology | 2016-2018
   Specialization: Machine Learning and Big Data Analytics

ğŸ“ Bachelor of Science in Computer Engineering  
   University of Texas at Austin | 2012-2016
   Minor in Mathematics

ğŸ“œ AWS Certified Big Data - Specialty (2023)
ğŸ“œ Google Cloud Professional Data Engineer (2022)
ğŸ“œ Databricks Certified Associate Developer for Apache Spark (2021)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECTS & ACHIEVEMENTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ† Built company's first real-time fraud detection system processing 1M transactions/hour
ğŸ† Designed data mesh architecture adopted across 5 business units
ğŸ† Open source contributor to Apache Airflow (3 merged PRs)
ğŸ† Speaker at PyCon 2023: "Building Resilient Data Pipelines"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CAREER OBJECTIVES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Seeking: Staff Data Engineer, Principal Data Engineer, or Data Architecture roles
Work Preference: Remote-first or hybrid (Austin, TX area)
Salary Range: $140,000 - $170,000 USD annually
Timeline: Available with 3 weeks notice
